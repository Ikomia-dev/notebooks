{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/Ikomia-dev/notebooks/blob/main/examples/img/banner_ikomia.png?raw=true'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy semantic segmentation with MMSegmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MMSegmentation** is part of the OpenMMLab project and is developed by the Multimedia Laboratory at the Chinese University of Hong Kong. It specializes in semantic segmentation, a vital component in the field of computer vision. \n",
    "\n",
    "It offers an extensive collection of segmentation models and algorithms, making it a go-to choice for both researchers and practitioners in the field.\n",
    "\n",
    "\n",
    "\n",
    "![MMSegmentation illustration](https://github.com/open-mmlab/mmsegmentation/blob/main/resources/seg_demo.gif?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to install Ikomia Python API with pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ikomia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MMSegmentation on your image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**-Google Colab ONLY- Restart runtime after the first run of the workflow below** \n",
    "\n",
    "Click on the \"RESTART RUNTIME\" button at the end the previous window.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "\n",
    "# Init your workflow\n",
    "wf = Workflow()\n",
    "\n",
    "# Add algorithm\n",
    "segmentor = wf.add_task(name=\"infer_mmlab_segmentation\", auto_connect=True)\n",
    "\n",
    "segmentor.set_parameters({\n",
    "        \"model_name\": \"pspnet\",\n",
    "        \"model_config\": \"pspnet_r50-d8_4xb2-40k_cityscapes-512x1024.py\",\n",
    "        \"cuda\": \"True\",\n",
    "    })\n",
    "\n",
    "\n",
    "# Run the workflow on image\n",
    "wf.run_on(url=\"https://github.com/open-mmlab/mmsegmentation/blob/main/demo/demo.png?raw=true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.core import IODataType\n",
    "from ikomia.utils.displayIO import display\n",
    "\n",
    "from PIL import ImageShow\n",
    "ImageShow.register(ImageShow.IPythonViewer(), 0)\n",
    "\n",
    "# Display the results\n",
    "display(segmentor.get_image_with_mask())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display legend\n",
    "results = segmentor.get_results()\n",
    "display(results.get_legend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of parameters\n",
    "\n",
    "- **model_name** (str, default=\"maskformer\"): model name. \n",
    "- **model_config** (str, default=\"maskformer_r50-d32_8xb2-160k_ade20k-512x512\"): name of the model configuration file.\n",
    "- **config_file** (str, default=\"\"): path to model config file (only if *use_custom_model=True*). The file is generated at the end of a custom training. Use algorithm ***train_mmlab_detection*** from Ikomia HUB to train custom model.\n",
    "- **model_weight_file** (str, default=\"\"): path to model weights file (.pt) (only if *use_custom_model=True*). The file is generated at the end of a custom training.\n",
    "- **cuda** (bool, default=True): CUDA acceleration if True, run on CPU otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMLab framework for object detection and instance segmentation offers a large range of models. To ease the choice of couple (model_name/model_config), you can call the function *get_model_zoo()* to get a list of possible values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "\n",
    "# Init your workflow\n",
    "wf = Workflow()\n",
    "\n",
    "# Add algorithm\n",
    "segmentor = wf.add_task(name=\"infer_mmlab_segmentation\", auto_connect=True)\n",
    "\n",
    "# Get list of possible models (model_name, model_config)\n",
    "models = segmentor.get_model_zoo()\n",
    "\n",
    "for model in models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MMSegmentation on Video\n",
    "*Note: The video stream will work on local only, not on Google Colab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "from ikomia.utils.displayIO import display\n",
    "import cv2\n",
    "\n",
    "# Use a path to your video\n",
    "video_input = 'PATH/TO/YOUR/VIDEO.mp4'  # Example video from Pexels: https://www.pexels.com/video/busy-street-in-new-york-854614/\n",
    "output_path = 'video_output.mp4'\n",
    "\n",
    "# Init your workflow\n",
    "wf = Workflow()\n",
    "\n",
    "# Add algorithm\n",
    "segmentor = wf.add_task(name=\"infer_mmlab_segmentation\", auto_connect=True)\n",
    "\n",
    "segmentor.set_parameters({\n",
    "    \"model_name\": \"segformer\",\n",
    "    \"model_config\": \"segformer_mit-b0_8xb1-160k_cityscapes-1024x1024\",\n",
    "    \"cuda\": \"True\",\n",
    "})\n",
    "\n",
    "# Open the video file from URL\n",
    "stream = cv2.VideoCapture(video_input)\n",
    "if not stream.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties for the output\n",
    "frame_width = int(stream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(stream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_rate = stream.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(output_path, fourcc, frame_rate, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    # Read image from stream\n",
    "    ret, frame = stream.read()\n",
    "    if not ret:\n",
    "        print(\"Info: End of video or error.\")\n",
    "        break\n",
    "\n",
    "    # Run the workflow on current frame\n",
    "    wf.run_on(array=frame)\n",
    "\n",
    "    # Get results\n",
    "    image_out = segmentor.get_output(0)\n",
    "    obj_detect_out = segmentor.get_output(1)\n",
    "\n",
    "    # Convert the result to BGR color space for displaying\n",
    "    img_out = image_out.get_image_with_mask_and_graphics(obj_detect_out)\n",
    "    img_res = cv2.cvtColor(img_out, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Save the resulting frame\n",
    "    out.write(img_res)  # This should be img_res instead of img_out if you intend to save the converted BGR image\n",
    "\n",
    "    # Display\n",
    "    display(img_res, title=\"MMSeg Semantic Segmentation\", viewer=\"opencv\")\n",
    "\n",
    "    # Press 'q' to quit the video processing\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release everything after the loop\n",
    "stream.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
