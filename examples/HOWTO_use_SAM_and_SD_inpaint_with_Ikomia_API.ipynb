{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/Ikomia-dev/notebooks/blob/main/examples/img/banner_ikomia.png?raw=true'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run SAM and stable diffusion inpainting with the Ikomia API "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image segmentation is a critical task in Computer Vision, enabling machines to understand and analyze the contents of images at a pixel level. The Segment Anything Model (SAM) is a groundbreaking instance segmentation model developed by Meta Research, which has taken the field by storm since its release in April 2023. SAM offers unparalleled versatility and efficiency in image analysis tasks, making it a powerful tool for a wide range of applications.\n",
    "\n",
    "SAM's Promptable Features\n",
    "SAM was specifically designed to address the limitations of existing image segmentation models and to introduce new capabilities that revolutionize the field. One of SAM's standout features is its promptable segmentation task, which allows users to generate valid segmentation masks by providing prompts such as spatial or text clues (feature not yet released at the time of writing) that identify specific objects within an image. This flexibility empowers users to obtain precise and tailored segmentation results effortlessly:\n",
    "1.\tGenerate segmentation masks for all objects SAM can detect.\n",
    "2.\tProvide boxes to guide SAM in generating a mask for specific objects in an image.\n",
    "3.\tProvide a box and a point to guide SAM in generating a mask with an area to exclude."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to install Ikomia Python API with pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ikomia numpy==1.23.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the SAM and stable diffusion inpaint algorithms on your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "from ikomia.utils import ik\n",
    "from ikomia.utils.displayIO import display\n",
    "\n",
    "# Init your workflow\n",
    "wf = Workflow()\n",
    "\n",
    "sam = wf.add_task(ik.infer_segment_anything(\n",
    "    model_name='vit_l',\n",
    "    input_box = '[204.8, 221.8, 769.7, 928.5]',\n",
    "    # draw_graphic_input = 'True', # LOCAL RUN ONLY, Set to true for drawing graphics using the API\n",
    "    ),\n",
    "    auto_connect=True\n",
    ")\n",
    "\n",
    "sd_inpaint = wf.add_task(ik.infer_hf_stable_diffusion_inpaint(\n",
    "    model_name = 'stabilityai/stable-diffusion-2-inpainting',\n",
    "    prompt = 'dog, high resolution',\n",
    "    negative_prompt = 'low quality',\n",
    "    num_inference_steps = '100',\n",
    "    guidance_scale = '7.5',\n",
    "    num_images_per_prompt = '1'),\n",
    "    auto_connect=True\n",
    ")\n",
    "\n",
    "# Run directly on your image\n",
    "wf.run_on(url=\"https://raw.githubusercontent.com/Ikomia-dev/notebooks/main/examples/img/img_cat.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display segmentation mask\n",
    "from PIL import ImageShow\n",
    "ImageShow.register(ImageShow.IPythonViewer(), 0)\n",
    "\n",
    "display(sam.get_image_with_mask())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inpainting output\n",
    "display(sd_inpaint.get_output(0).get_image())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Google Colab ONLY- Save your custom image in your Google Drive space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines if you're working on Colab\n",
    "\"\"\" from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "cv2.imwrite(\"/content/gdrive/MyDrive/paint_img.png\", img_paint) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Google Colab ONLY- Download directly your custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these lines if you're working on Colab\n",
    "\"\"\" from google.colab import files\n",
    "cv2.imwrite(\"/content/paint_img.png\", img_paint)\n",
    "files.download('/content/paint_img.png') \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvapi",
   "language": "python",
   "name": "venvapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
