{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GyGbD_GxAOI0"
   },
   "source": [
    "<img src='https://github.com/Ikomia-dev/notebooks/blob/main/examples/img/banner_ikomia.png?raw=true'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WKz9Zij7bN-t"
   },
   "source": [
    "# How to train YOLO v7 using the Ikomia API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "CpxHrXhtbWTZ"
   },
   "source": [
    "Object detection is an important task in Computer Vision. Lots of companies use this technology:\n",
    "\n",
    "\n",
    "*   **Smart city** : crowd analysis or infrastructure inspection\n",
    "*   **Retail** : inventory tracking or customer tracking\n",
    "*   **Autonomous vehicles** : vehicle or pedestrian detection\n",
    "*   **Security** : facial recognition or potential threats detection\n",
    "*   **Manufacturing** : quality control or defect detection\n",
    "*   **Healthcare** : many disease recognition\n",
    "\n",
    "\n",
    "### Overview of the YOLOv7 model\n",
    "\n",
    "| Release date | July 2022        |\n",
    "|--------------|------------------|\n",
    "| Model type   | Object detection |\n",
    "| Architecture | YOLO, CNN        |\n",
    "| Framework    | PyTorch          |\n",
    "| Github stars | >10k             |\n",
    "\n",
    "Compared to its predecessors, YOLOv7 introduces several architectural reforms that contribute to improved performance. These include:\n",
    "- Architectural reform:\n",
    "  - Model scaling for concatenation-based models\n",
    "  - E-ELAN (Extended Efficient Layer Aggregation Network)\n",
    "- Trainable Bag-of-Freebies (BoF)\n",
    "  - Planned re-parameterized convolution.\n",
    "  - Coarse for auxiliary and fine for lead loss  \n",
    "\n",
    "These enhancements result in a 13.7% higher Average Precision (AP) on the COCO dataset compared to YOLOv6.\n",
    "\n",
    "\n",
    "- Paper : [YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors](https://arxiv.org/abs/2207.02696)\n",
    "\n",
    "- Code : [GitHub repository](https://github.com/wongkinyiu/yolov7)\n",
    "\n",
    "If you like this tutorial, you can support our project here [Ikomia API GitHub](https://github.com/Ikomia-dev/IkomiaApi).\n",
    "\n",
    "ENJOY ðŸ¥° !!\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"https://github.com/Ikomia-dev/notebooks/blob/main/examples/img/img_aerial.jpg?raw=true\" width=\"400\" /> \n",
    "  <img src=\"https://github.com/Ikomia-dev/notebooks/blob/main/examples/img/img_aerial_bbox.png?raw=true\" width=\"400\" />\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "x4CdI0J1ej5b"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "R5O31W412NRx"
   },
   "source": [
    "Please use a GPU for this tutorial.\n",
    "\n",
    "In the menu, select \"Runtime\" then \"Change runtime type\", choose GPU in \"Hardware accelerator\".\n",
    "\n",
    "Check your GPU with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJFMsi47Yrqj"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NBmJN2AaDmcI"
   },
   "source": [
    "First of all, you need to install Ikomia API pip package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8eSnQYJygrDy"
   },
   "outputs": [],
   "source": [
    "!pip install ikomia numpy==1.23.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ktbA-VPOATgP"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**-Google Colab ONLY- Restart runtime**\n",
    "\n",
    "Click on the \"RESTART RUNTIME\" button at the end the previous window.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2hS1T6ky1Wcw"
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JJsRFzl9Au1c"
   },
   "source": [
    "Ikomia API has already more than 280 pre-integrated algorithms but the most interesting algorithms are in [Ikomia HUB](https://github.com/Ikomia-hub). \n",
    "\n",
    "We push regularly state-of-the-art algorithms from individual repos (think of YOLO v7 for example) or from companies (Facebook Detectron2 or Ultralytics/YOLOv5 for example)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZgGi5tjosC8g"
   },
   "source": [
    "## How to train YOLO v7 on a custom YOLO dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pwJit3k190PN"
   },
   "source": [
    "Download your dataset from your preferred tool. In this example, we use a dataset from **Roboflow** which is a great annotation platform used by many developers and companies. The dataset is exported in YOLO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpGiTWgeRnIq"
   },
   "outputs": [],
   "source": [
    "!curl -L \"https://universe.roboflow.com/ds/W8grf6DmCF?key=QkQVA4pg66\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "!cp $(pwd)/valid/* $(pwd)/train/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BgYm8QNx-ekO"
   },
   "source": [
    "In order to train YOLOv7 on your custom dataset, please create a new workflow from scratch.\n",
    "\n",
    "Then you need 2 components:\n",
    "\n",
    "1.   A YOLO dataset loader which loads dataset in YOLO format and convert it to an Ikomia format\n",
    "2.   The YOLOv7 training algorithm which loads dataset in Ikomia format\n",
    "\n",
    "Add these 2 previous algorithms to your workflow and then it will automagically download all algorithms from Ikomia Hub and install all the Python dependencies (the 1st time, it can take a while, be patient ! )."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jYEO6THt85ml"
   },
   "source": [
    "** -Google Colab ONLY- ** \n",
    "If you want to monitor your training results, you can use TensorBoard by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlLFhQwCZIJS"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /root/Ikomia/Tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "I1BKL7hpw15Z"
   },
   "source": [
    "Now, it's time to train your model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfICgCeQLJuc"
   },
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "from ikomia.utils import ik\n",
    "import os\n",
    "\n",
    "#----------------------------- Step 1 -----------------------------------#\n",
    "# Create a workflow which will take your dataset as input and\n",
    "# train a YOLOv7 model on it\n",
    "#------------------------------------------------------------------------#\n",
    "wf = Workflow()\n",
    "\n",
    "#----------------------------- Step 2 -----------------------------------#\n",
    "# First you need to convert darknet YOLO format to IKOMIA format.\n",
    "# Add an Ikomia dataset converter to your workflow.\n",
    "#------------------------------------------------------------------------#\n",
    "dataset_yolo = wf.add_task(ik.dataset_yolo(dataset_folder=os.getcwd()+\"/train\", class_file=os.getcwd()+\"/train/_darknet.labels\"))\n",
    "\n",
    "#----------------------------- Step 3 -----------------------------------#\n",
    "# Then, you want to train a YOLOv7 model.\n",
    "# Add YOLOv7 training algorithm to your workflow\n",
    "#------------------------------------------------------------------------#\n",
    "yolo7 = wf.add_task(ik.train_yolo_v7(output_folder=os.getcwd(), batch_size=\"16\", epochs=\"10\"), auto_connect=True)# <-- Reduce the batch size if you encounter some \"Cuda out of memory\"\n",
    "\n",
    "#----------------------------- Step 4 -----------------------------------#\n",
    "# Execute your workflow.\n",
    "# It automatically runs all your tasks sequentially.\n",
    "#------------------------------------------------------------------------#\n",
    "wf.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rpsaQoYSwma8"
   },
   "source": [
    "## How to execute YOLOv7 on images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-H2JCp2SOD2a"
   },
   "source": [
    "Once the training is finished, you may want to experiment the fresh model on new test images. Just use the following code to create a YOLO v7 inference workflow.\n",
    "Then run and test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecT5qPDywrEi"
   },
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "from ikomia.utils import ik\n",
    "\n",
    "# Create your workflow for YOLO inference\n",
    "wf = Workflow()\n",
    "\n",
    "# Add YOLO v7 to your workflow\n",
    "yolov7 = wf.add_task(ik.infer_yolo_v7(model_weight_file=os.getcwd()+\"/[timestamp]/weights/best.pt\", conf_thres=\"0.4\"), auto_connect=True) # <-- replace \"[timestamp]\" by the correct folder name (/content/ for Google Colab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and display your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.utils.displayIO import display\n",
    "from PIL import ImageShow\n",
    "ImageShow.register(ImageShow.IPythonViewer(), 0)\n",
    "\n",
    "# Apply YOLO v7 on your image\n",
    "# By default, YOLOv7 runs with a pre-trained model based on COCO\n",
    "# To use your custom model, set the parameters in the previous cell\n",
    "wf.run_on(path=os.getcwd()+\"/test/airport_246_jpg.rf.3d892810357f48026932d5412fa81574.jpg\")\n",
    "\n",
    "# Get YOLO v7 image result\n",
    "img_bbox = yolov7.get_image_with_graphics()\n",
    "\n",
    "# Display in Colab\n",
    "display(img_bbox)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "e8NF6rmzkNjT"
   },
   "source": [
    "## -Google Colab ONLY- Save your YOLO v7 model in your Google Drive account\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8tbX9joziSxe",
    "outputId": "83649d92-c555-4ef3-cf7e-54dd14669a68"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# Uncomment and insert the correct \"folder name\" in the following path\n",
    "#%cp /content/folder_name/weights/best.pt /content/gdrive/MyDrive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DyS-Lak6kntB"
   },
   "source": [
    "## -Google Colab ONLY- Download directly your custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "s_E2W_3hk07U",
    "outputId": "41ba4234-45b5-4958-804e-4ea3e4d9a5e1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "# Uncomment and insert the correct \"folder name\" in the following path\n",
    "#files.download('/content/folder_name/weights/best.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venvapi",
   "language": "python",
   "name": "venvapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
