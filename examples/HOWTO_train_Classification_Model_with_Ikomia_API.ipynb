{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/Ikomia-dev/notebooks/blob/main/examples/img/banner_ikomia.png?raw=true'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train a classification model on a Custom Dataset with the Ikomia API\n",
    "\n",
    "Image classification is a fundamental task in computer vision that involves categorizing images into predefined classes based on their visual content. It enables computers to recognize objects, scenes, and patterns within images. The importance of image classification lies in its various applications:\n",
    "\n",
    "-\t**Object Recognition**: It allows computers to identify and categorize objects in images, essential for applications like autonomous vehicles and surveillance systems.\n",
    "-\t**Image Understanding**: Classification helps machines interpret image content and extract meaningful information, enabling advanced analysis and decision-making based on visual data.\n",
    "-\t**Visual Search and Retrieval**: By assigning tags or labels to images, classification models facilitate efficient searching and retrieval of specific images from large databases.\n",
    "-\t**Content Filtering and Moderation**: Image classification aids in automatically detecting and flagging inappropriate or offensive content, ensuring safer online environments.\n",
    "-\t**Medical Imaging and Diagnosis**: Classification assists in diagnosing diseases and analyzing medical images, enabling faster and more accurate diagnoses.\n",
    "-\t**Quality Control and Inspection**: By classifying images, defects or anomalies in manufactured products can be identified, ensuring quality control in various industries-\n",
    "-\t**Visual Recommendation Systems**: Image classification enhances recommendation systems by analyzing visual content and suggesting related items or content.\n",
    "-\t**Security and Surveillance**: Classification enables the identification of objects or individuals of interest in security and surveillance applications, enhancing threat detection and public safety.\n",
    "\n",
    "\n",
    "In summary, image classification is essential for object recognition, image understanding, search and retrieval, content moderation, medical imaging, quality control, recommendation systems, and security applications in computer vision.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Please use a GPU for this tutorial.\n",
    "\n",
    "In the menu, select \"Runtime\" then \"Change runtime type\", choose GPU in \"Hardware accelerator\".\n",
    "\n",
    "Check your GPU with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, you need to install Ikomia API pip package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ikomia numpy==1.23.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**-Google Colab ONLY- Restart runtime**\n",
    "\n",
    "Click on the \"RESTART RUNTIME\" button at the end the previous window.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ikomia API has already more than 280 pre-integrated algorithms but the most interesting algorithms are in [Ikomia HUB](https://github.com/Ikomia-hub). \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train TorchVision ResNet on a custom datasetÂ¶"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download your dataset from your preferred tool. In this example, we use a dataset from **Roboflow** which is a great annotation platform used by many developers and companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L \"https://universe.roboflow.com/ds/48QIfZoFjO?key=NTZLzFA0Q2\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**-Google Colab ONLY-** \n",
    "\n",
    "If you want to monitor your training results, you can use TensorBoard by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /root/Ikomia/Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "from ikomia.utils.displayIO import display\n",
    "from ikomia.utils import ik\n",
    "import os\n",
    "\n",
    "# Init your workflow\n",
    "wf = Workflow()\n",
    "\n",
    "# Add the training task to the workflow\n",
    "resnet = wf.add_task(ik.train_torchvision_resnet(\n",
    "                                model_name=\"resnet34\",\n",
    "                                batch_size=\"16\",\n",
    "                                epochs=\"50\",\n",
    "                                output_folder=os.getcwd(),\n",
    "                                ),\n",
    "                            auto_connect=True\n",
    "                            )\n",
    "\n",
    "# Set the input path of your dataset\n",
    "dataset_folder = \"./Rock Paper Scissors.v1-hugggingface.folder\"\n",
    "\n",
    "# Launch your training on your data\n",
    "wf.run_on(folder=dataset_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to execute YOLOv7 on images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training is finished, you may want to experiment the fresh model on new test images. Just use the following code to create a TorchVision ResNet inference workflow.\n",
    "Then run and test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "from ikomia.utils import ik\n",
    "\n",
    "# Create your workflow for classification inference\n",
    "wf = Workflow()\n",
    "\n",
    "# Add TorchVision ResNet to your workflow\n",
    "resnet = wf.add_task(ik.infer_torchvision_resnet(\n",
    "    model_name=\"resnet34\",\n",
    "    model_weight_file=os.getcwd()+\"/[timestamp]/resnet34.pth\",\n",
    "    class_file=os.getcwd()+\"/[timestamp]/classes.txt\"), \n",
    "    auto_connect=True\n",
    ") # <-- replace \"[timestamp]\" by the correct folder name (/content/ for Google Colab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and display your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.utils.displayIO import display\n",
    "from PIL import ImageShow\n",
    "ImageShow.register(ImageShow.IPythonViewer(), 0)\n",
    "\n",
    "# Apply YOLO v7 on your image\n",
    "# By default, YOLOv7 runs with a pre-trained model based on COCO\n",
    "# To use your custom model, set the parameters in the previous cell\n",
    "wf.run_on(path=os.getcwd()+\"/Rock Paper Scissors.v1-hugggingface.folder/val/rock/testrock01-22_png.rf.bfdd5a8de97b79d792c670fcc7223b45.jpg\")\n",
    "\n",
    "# Get YOLO v7 image result\n",
    "result = resnet.get_image_with_graphics()\n",
    "\n",
    "# Display in Colab\n",
    "display(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvapi",
   "language": "python",
   "name": "venvapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
