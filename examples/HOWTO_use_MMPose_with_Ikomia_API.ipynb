{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/Ikomia-dev/notebooks/blob/main/examples/img/banner_ikomia.png?raw=true'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy pose estimation with MMPose "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the world of Computer Vision, pose estimation aims to determine the position and orientation of predefined keypoints on objects or body parts. For instance, in human pose estimation, the goal is to locate specific keypoints on a person's body, such as the elbows, knees, and shoulders.\n",
    "\n",
    "\n",
    "MMPose, a part of the OpenMMLab's ecosystem, is a cutting-edge library that provides tools and frameworks specifically designed for various pose estimation tasks.\n",
    "\n",
    "\n",
    "![MMPose illustration](https://uploads-ssl.webflow.com/645cec60ffb18d5ebb37da4b/65095ef33bca342892d5fbe4_220008302-4a57fd44-0978-408e-8351-600e5513316a.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to install Ikomia Python API with pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ikomia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MMPose on your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ikomia.dataprocess.workflow import Workflow\n",
    "from ikomia.utils import ik\n",
    "from ikomia.utils.displayIO import display\n",
    "\n",
    "# Init your workflow\n",
    "wf = Workflow()\n",
    "\n",
    "# Add the MMpose algorithm\n",
    "pose = wf.add_task(ik.infer_mmlab_pose_estimation(\n",
    "        config_file = \"configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_vipnas-mbv3_8xb64-210e_coco-256x192.py\",\n",
    "        conf_thres = '0.5',\n",
    "        conf_kp_thres = '0.3',\n",
    "        detector = \"Person\"\n",
    "        ),\n",
    "        auto_connect=True\n",
    ")\n",
    "\n",
    "# Run directly on your image\n",
    "wf.run_on(url=\"https://cdn.nba.com/teams/legacy/www.nba.com/bulls/sites/bulls/files/jordan_vs_indiana.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the keypoints\n",
    "from PIL import ImageShow\n",
    "ImageShow.register(ImageShow.IPythonViewer(), 0)\n",
    "\n",
    "display(pose.get_image_with_graphics())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvapi",
   "language": "python",
   "name": "venvapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
